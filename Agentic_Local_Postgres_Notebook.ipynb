{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Local Agentic PostgreSQL Bundle (Postgres 16) — Notebook\n",
    "\n",
    "This notebook guides you through launching a local Postgres 16 instance via Docker Compose, populating it with sample e-commerce and observability data, and running simple integration tests.\n",
    "\n",
    "Files created in `/mnt/data/agentic_local_bundle`:\n",
    "\n",
    "- `docker-compose.yml` — Postgres 16 service\n",
    "- `initdb/init.sql` — schema + extensions\n",
    "- `generate_data.py` — Python script to populate datasets\n",
    "- `tests/test_agent.py` — pytest harness\n",
    "\n",
    "Run the commands in the following cells in your local environment (they will not run in this sandbox).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1) Start Postgres with Docker Compose\n",
    "\n",
    "From the directory containing `docker-compose.yml` run:\n",
    "\n",
    "```bash\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "This will expose Postgres on `localhost:5432` with credentials `agentic/agentic_pass` and database `agentic_db`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: bring up Docker Compose (DO NOT RUN in this sandbox)\n",
    "!docker compose -f /mnt/data/agentic_local_bundle/docker-compose.yml up -d\n",
    "print('docker compose up requested')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2) Wait for DB and generate dataset\n",
    "\n",
    "Run the Python data generator to populate the database. By default it seeds 50 customers, 40 products, 200 orders, 1000 metrics, 50 alerts, 500 logs.\n",
    "\n",
    "```bash\n",
    "python /mnt/data/agentic_local_bundle/generate_data.py --customers 50 --products 40 --orders 200 --metrics 1000 --alerts 50 --logs 500\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: run generator from the notebook (DO NOT RUN here)\n",
    "!python /mnt/data/agentic_local_bundle/generate_data.py --customers 50 --products 40 --orders 200 --metrics 1000 --alerts 50 --logs 500\n",
    "print('data generation requested')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3) Quick sanity-check queries\n",
    "\n",
    "Use SQLAlchemy to connect and run example queries against commerce and observability schemas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example queries (DO NOT RUN in this sandbox)\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "\n",
    "PG_USER = os.getenv('PGUSER','agentic')\n",
    "PG_PASS = os.getenv('PGPASSWORD','agentic_pass')\n",
    "PG_HOST = os.getenv('PGHOST','localhost')\n",
    "PG_PORT = os.getenv('PGPORT','5432')\n",
    "PG_DB   = os.getenv('PGDB','agentic_db')\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{PG_USER}:{PG_PASS}@{PG_HOST}:{PG_PORT}/{PG_DB}')\n",
    "with engine.connect() as conn:\n",
    "    q1 = text(\"SELECT p.name, SUM(oi.quantity*oi.unit_price) as revenue FROM commerce.order_items oi JOIN commerce.products p ON oi.product_id = p.id GROUP BY p.name ORDER BY revenue DESC LIMIT 5\")\n",
    "    res = conn.execute(q1).fetchall()\n",
    "    print('Top products by revenue:', res)\n",
    "\n",
    "    q2 = text(\"SELECT alert_name, COUNT(*) as c FROM observability.alerts GROUP BY alert_name ORDER BY c DESC LIMIT 5\")\n",
    "    res2 = conn.execute(q2).fetchall()\n",
    "    print('Top alerts:', res2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 4) Run tests\n",
    "\n",
    "From the bundle directory run:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt  # see requirements below\n",
    "pytest -q /mnt/data/agentic_local_bundle/tests\n",
    "```\n",
    "\n",
    "Expected: tests pass if DB is up and data generated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 5) Requirements\n",
    "\n",
    "Install these locally in your virtualenv:\n",
    "\n",
    "```bash\n",
    "pip install sqlalchemy psycopg2-binary psycopg2 pytest psycopg2-binary\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 6) Next: LangChain integration\n",
    "\n",
    "Once the DB is up and seeded, continue with the LangChain notebook (or the earlier notebook scaffolds) to connect the agent in read-only mode and run example prompts.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
